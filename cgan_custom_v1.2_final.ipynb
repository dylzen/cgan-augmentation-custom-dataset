{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "pyplot per i grafici\n",
    "\n",
    "numpy per la gestione degli array/tensori\n",
    "\n",
    "os, glob, pathlib per gestione filesystem/cartelle/files\n",
    "\n",
    "wandb per il tracking degli esperimenti\n",
    "\n",
    "pandas per il dataframe proveniente dal .csv\n",
    "\n",
    "time per aggiungere il timestamp al file del modello e delle immagini sintetiche\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definizione iperparametri\n",
    "Frutto di lungo processo di trial/error. I valori dei learning rates utilizzati (per l'algoritmo Adam) evitano che le funzioni di costo di discriminator e generator non divergano dopo poche decine di epochs, consentendo un training stabile per oltre 1500 epochs (~2h su Colab, 4h sul mio hardware)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8          # default tutorial MNIST = 64, default Gennaro = 5\n",
    "num_channels = 1\n",
    "num_classes = 2         # default MNIST = 10 (cifre 0-9), ora Healthy o Patient -> 2\n",
    "image_size = 64         # i .png del dataset sono 64x64\n",
    "latent_dim = 128        # provato 256 per ovviare al mode collapse, poca differenza\n",
    "\n",
    "lr_disc = 0.00002       \n",
    "lr_gen = 0.00002        # default ADAM = 0.001, default tutorial MNIST = 0.0003, divergono (g_loss altissima)\n",
    "decay_disc = 0.9        # default = 0.9, provato 0.5 ma diverge\n",
    "decay_gen = 0.9         # default = 0.9, provato 0.5 ma diverge\n",
    "n_epochs = 501         \n",
    "lbl_smooth = 0          \n",
    "patience = 200        # valore per l'EarlyStopping usato per i primi addedstramenti\n",
    "loss_func = \"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Controllo percorsi e visualizzo immagini del dataset dal filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = str(pathlib.Path.home())\n",
    "dataset_dir = pathlib.PurePath(home_path, 'Documents', 'Neural Networks', 'datasets')\n",
    "print(f'Cartella dei datasets:', dataset_dir)\n",
    "\n",
    "seed_name = \"meander02\"\n",
    "src_path_train = pathlib.PurePath(dataset_dir, 'accXaccY', '64', '50_50', 'meander', '02', 'training')\n",
    "print(f'Cartella del dataset di training', src_path_train)\n",
    "\n",
    "sub_class = [f for f in os.listdir(src_path_train) if not f.startswith('.')]\n",
    "print(f'Labels trovate nei dati di training:', sub_class)\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "path = os.path.join(src_path_train,sub_class[0])\n",
    "\n",
    "filelist = glob.glob(path+'/*')\n",
    "\n",
    "for i in range(4):\n",
    "    print(filelist[i])\n",
    "    plt.subplot(240 + 1 + i)\n",
    "    img = plt.imread(filelist[i])\n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "src_path_test = pathlib.PurePath(dataset_dir, 'accXaccY', '64', '50_50', 'meander', '02', 'test')\n",
    "print(f'\\nCartella del dataset di test' ,src_path_test)\n",
    "\n",
    "sub_class = [f for f in os.listdir(src_path_test) if not f.startswith('.')]\n",
    "print(f'Labels trovate nei dati di test:', sub_class)\n",
    "\n",
    "path = os.path.join(src_path_test, sub_class[1])\n",
    "\n",
    "filelist = glob.glob(path+'/*')\n",
    "for i in range(4,8):\n",
    "    print(filelist[i])\n",
    "    plt.subplot(240 + 1 + i)\n",
    "    img = plt.imread(filelist[i])\n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carico il dataset tramite il metodo di keras 'image_dataset_from_directory'\n",
    "Il metodo genera un oggetto \"tf.data.Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=src_path_train,\n",
    "    validation_split=0.3,                   # stesso usato da Gennaro\n",
    "    subset='training',                      # divisione del set\n",
    "    labels='inferred',                      # prende i modi delle classi dalle sottocartelle del set\n",
    "    label_mode='categorical',               # labels sono codificate come categorical vector con valori binari (sostituisce il metodo utils.to_categorical)\n",
    "    class_names=['H', 'P'],                 # devono corrispondere ai nomi delle sottocartelle\n",
    "    color_mode='grayscale',                 # canale dei colori\n",
    "    batch_size=batch_size,                  \n",
    "    image_size=(image_size, image_size),\n",
    "    shuffle=False,                          # uso il seed originale, senza modificare l'ordine dei samples\n",
    "    # seed=123\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=src_path_train,\n",
    "    validation_split=0.3,\n",
    "    subset='validation',\n",
    "    image_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode='categorical',\n",
    "    class_names=['H', 'P'],\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=False,\n",
    "    # seed=123\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory = src_path_test,\n",
    "    labels = \"inferred\",\n",
    "    label_mode='categorical',\n",
    "    class_names = ['H', 'P'],\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size = batch_size,                         # uso un singolo sample come batch per la fase di test\n",
    "    image_size = (image_size, image_size),\n",
    "    shuffle = False,\n",
    "    # seed=123\n",
    ")\n",
    "\n",
    "# Verifico corretto caricamento dei diversi sets e delle labels\n",
    "class_names_train = train_ds.class_names\n",
    "print(f'Lista delle classi (train): {class_names_train}')\n",
    "\n",
    "class_names_test = test_ds.class_names\n",
    "print(f'Lista delle classi (test): {class_names_test}')\n",
    "\n",
    "n_classes = len(class_names_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salvo numero di samples per ogni set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [item for item in os.listdir(src_path_train) if os.path.isdir(os.path.join(src_path_train, item))]\n",
    "nb_train_samples = ( sum([len(files) for _, _, files in os.walk(src_path_train)]) - 1 )\n",
    "nb_validation_samples = round(nb_train_samples * 0.3) - 1\n",
    "validation_steps = nb_validation_samples / batch_size\n",
    "nb_synth_samples = 0\n",
    "nb_test_samples = ( sum([len(files) for _, _, files in os.walk(src_path_test)]) - 1)\n",
    "total_nb_samples = nb_train_samples + nb_test_samples\n",
    "nb_classes = len(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizzo immagini dopo aver caricato il dataset\n",
    "Mi assicuro che il dataset venga caricato correttamente, con le labels come titolo\n",
    "\n",
    "[1. 0.] = Healthy\n",
    "\n",
    "[0. 1.] = Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in train_ds.shuffle(buffer_size=5).take(1):\n",
    "  print(images.shape)\n",
    "  for i in range(5):\n",
    "    ax = plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(images[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(np.array(labels[i]))\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_ds.shuffle(buffer_size=5).take(1):\n",
    "  for i in range(5):\n",
    "    ax = plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(images[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(np.array(labels[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verifica shapes di immagini e labels\n",
    "mi deve restituire:\n",
    "\n",
    "(batch_size, 64, 64, 1) per le immagini\n",
    "\n",
    "(batch_size, 2) per le labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(f'Shape delle immagini di training (batch):', image_batch.shape)\n",
    "  # print(image_batch[0])\n",
    "  print(f'Shape delle labels di training (batch):', labels_batch.shape)\n",
    "  print(labels_batch[0])\n",
    "  break\n",
    "\n",
    "for image_batch, labels_batch in test_ds:\n",
    "  print(f'Shape delle immagini di test (batch):', image_batch.shape)\n",
    "  # print(image_batch[0])\n",
    "  print(f'Shape delle labels di test (batch):', labels_batch.shape)\n",
    "  print(labels_batch[0])\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardizzo i dati\n",
    "Normalizzo i valori nell'intervallo [0,1] per utilizzare un'attivazione di tipo \"sigmoid\" nei modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)                         # per normalizzare in [0, 1]\n",
    "nl = '01'\n",
    "# normalization_layer = tf.keras.layers.Rescaling(1./127.5, offset=-1)          # per normalizzare in [-1, 1]\n",
    "# nl = '-11'\n",
    "normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_train_ds))\n",
    "first_image = image_batch[0]\n",
    "first_label = labels_batch[0]\n",
    "# Testo che i valori siano effettivamente in [0,1]\n",
    "print(\"Intervallo train set: \", np.min(first_image), np.max(first_image))\n",
    "print(\"Intervallo labels: \", np.min(first_label), np.max(first_label))\n",
    "\n",
    "normalized_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_val_ds))\n",
    "first_image = image_batch[0]\n",
    "# Testo che i valori siano effettivamente in [0,1].\n",
    "print(\"Intervallo validation set: \", np.min(first_image), np.max(first_image))\n",
    "\n",
    "normalized_test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_test_ds))\n",
    "first_image = image_batch[0]\n",
    "# Testo che i valori siano effettivamente in [0,1].\n",
    "print(\"Intervallo test set: \", np.min(first_image), np.max(first_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definisco numero di canali in input alle due reti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_in_channels = latent_dim + num_classes        # 128 punti dello spazio + numero classi (H/P)\n",
    "discriminator_in_channels = num_channels + num_classes  # numero di canali (1=grayscale) + num classi (H/P)\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definizione modelli\n",
    "Sia Generatore che Discriminatore sono definite tramite le Sequential API di Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)         # best practice per stabilizzare il training di una DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generatore e Discriminatore\n",
    "\n",
    "Implementazione DCGAN\n",
    "\n",
    "https://keras.io/examples/generative/dcgan_overriding_train_step/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "discriminator = tf.keras.Sequential(\n",
    "    [\n",
    "        # L'input al generatore è un sample (reale o sintetico) con shape (64,64,num_canali+num_classi)\n",
    "        tf.keras.layers.InputLayer(input_shape=(64, 64, discriminator_in_channels), name=\"disc_input\"),\n",
    "        # (64,64,3) -> (32,32,64) = downsampling\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\", name=\"conv1\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2, name=\"relu1\"), # best practice\n",
    "        # (32,32,64) -> (16,16,128) = downsampling\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\", name=\"conv2\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2, name=\"relu2\"),\n",
    "        # (16,16,128) -> (8,8,128) = downsampling\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\", name=\"conv3\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2, name=\"relu3\"),\n",
    "        tf.keras.layers.Flatten(name=\"flatten1\"),\n",
    "        tf.keras.layers.Dropout(0.2, name=\"dropout1\"),\n",
    "        # (8,8,128) -> prediction (fake/real)\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "# Mi assicuro che l'output abbia la giusta shape\n",
    "assert discriminator.output_shape == (None, 1)\n",
    "discriminator.summary()\n",
    "\n",
    "generator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(input_shape=(generator_in_channels,), name=\"gen_input\"),\n",
    "        # Vogliamo generare latent_dim(128) + num_classes coefficienti per ricostruirli in una map da\n",
    "        # 8x8x(128 + num_classes).\n",
    "        tf.keras.layers.Dense((8 * 8 * generator_in_channels), name=\"dense1\"),\n",
    "        tf.keras.layers.Reshape((8, 8, generator_in_channels), name=\"reshape1\"),\n",
    "        # kernel deve avere dim multiple dello stride (no checkerboard effect)\n",
    "        # (8,8,latent_dim+n_classes) -> (16,16,128) = upsampling  \n",
    "        tf.keras.layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\", name=\"t_conv1\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2, name=\"relu1\"),  # best practice\n",
    "        # (16,16,128) -> (32,32,256) = upsampling\n",
    "        tf.keras.layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\", name=\"t_conv2\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2, name=\"relu2\"),\n",
    "        # (32,32,256) -> (64,64,512) = upsampling\n",
    "        tf.keras.layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\", name=\"t_conv3\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2, name=\"relu3\"),\n",
    "        # (64,64,512) -> (64,64,1) = output, immagine 64x64 greyscale\n",
    "        tf.keras.layers.Conv2D(1, kernel_size=5, padding=\"same\", activation=\"sigmoid\", name=\"output\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "# Mi assicuro che l'output abbia la giusta shape\n",
    "assert generator.output_shape == (None, 64, 64, 1)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model=discriminator, to_file=\"generator_graph.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model=generator, to_file=\"generator_graph.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uso il generatore non addestrato per generare un'immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([2,generator_in_channels])\n",
    "generated_image = generator(noise, training=False)\n",
    "print(generated_image.shape)\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model subclassing e override dei metodi train_step e test_step\n",
    "\n",
    "Implementazione CGAN\n",
    "\n",
    "https://keras.io/examples/generative/conditional_gan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConditionalGAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"g_loss\")\n",
    "        self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"d_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker, self.train_mse_metric, self.train_acc_metric]   # aggiunto le due metriche custom (MSE e Accuracy)\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn, train_mse_metric, train_acc_metric):                   # aggiunto le due metriche custom (MSE e Accuracy)\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_mse_metric = train_mse_metric # MSE\n",
    "        self.train_acc_metric = train_acc_metric # BinaryAccuracy\n",
    "    \n",
    "    # Le sezioni commentate in inglese sono quelle di default e non sono state modificate   \n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "        \n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights))\n",
    "        \n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        \n",
    "        # Aggiungo le metriche richieste\n",
    "        self.train_acc_metric.update_state(labels, self.discriminator(combined_images, training=True))\n",
    "        self.train_mse_metric.update_state(labels, self.discriminator(combined_images, training=True))\n",
    "        # Restituisco tutte le metriche\n",
    "        return { m.name: m.result() for m in self.metrics }\n",
    "    \n",
    "    # override del test step per implementazione di model.evaluate e aggiunta metriche\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "        \n",
    "        # Da qui in poi aggiungo le loss e le metriche evitando backpropagation e training\n",
    "        val_d_logits = self.discriminator(combined_images, training=False)\n",
    "        val_g_logits = self.discriminator(fake_image_and_labels, training=False)\n",
    "\n",
    "        # Compute the loss value\n",
    "        self.val_d_loss_value = self.loss_fn(labels, val_d_logits)\n",
    "        self.val_g_loss_value = self.loss_fn(misleading_labels, val_g_logits)\n",
    "        \n",
    "        # Monitor loss.\n",
    "        self.disc_loss_tracker.update_state(self.val_d_loss_value)\n",
    "        self.gen_loss_tracker.update_state(self.val_g_loss_value)\n",
    "        # Aggiungo le metriche richieste\n",
    "        self.train_acc_metric.update_state(labels, self.discriminator(combined_images, training=False))\n",
    "        self.train_mse_metric.update_state(labels, self.discriminator(combined_images, training=False))\n",
    "        \n",
    "        # Restituisco tutte le metriche\n",
    "        return { m.name: m.result() for m in self.metrics }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging e tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definizione dei Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "log_dir = os.path.join(os.getcwd(), 'logs')\n",
    "csv_dir = os.path.join(log_dir, 'csv')\n",
    "model_checkpoints_dir = os.path.join(log_dir, 'model_checkpoints')\n",
    "model_checkpoints_timestamp = pathlib.Path(model_checkpoints_dir, timestr)\n",
    "model_checkpoints_timestamp.mkdir(parents=True, exist_ok=True)\n",
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = pathlib.Path(model_checkpoints_timestamp, \"cp-epo{epoch:04d}-g_loss{g_loss:.2f}-d_loss{d_loss:.2f}-acc{accuracy:.2f}-mse{mse:.2f}\")\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "print(checkpoint_path)\n",
    "print(checkpoint_dir)\n",
    "\n",
    "csv_file = csv_dir + '/training_results_' + str(seed_name) + \"_epoch\" + str(n_epochs) + \"_\" + str(timestr) + '.csv'\n",
    "print(csv_file)\n",
    "\n",
    "def get_callbacks(log_dir):\n",
    "  return [\n",
    "    tf.keras.callbacks.EarlyStopping(   # usato solo inizialmente quando le loss divergevano subito\n",
    "      monitor='g_loss',\n",
    "      patience=patience,\n",
    "      verbose=1,\n",
    "      restore_best_weights=True,\n",
    "    ),\n",
    "    tf.keras.callbacks.CSVLogger(csv_file),   # costruisco un file csv con tutte le metriche\n",
    "    tf.keras.callbacks.ModelCheckpoint(       # per salvare i modelli (circa 50MB per checkpoint). Salvo solo weights perchè non posso salvare l'intero modello con subclassing\n",
    "      filepath=checkpoint_path,\n",
    "      # monitor='val_g_loss',\n",
    "      verbose=1,\n",
    "      save_best_only=False,\n",
    "      save_weights_only=True,\n",
    "      save_freq='epoch',\n",
    "      period=10,\n",
    "    )\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom callback per la generazione di immagini durante il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images_dir = \"logs/generated_images/training\"\n",
    "timestamp_dir = pathlib.Path(generated_images_dir, timestr)\n",
    "timestamp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class GANMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=generator_in_channels):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # start = time.time()\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            if (epoch+1) % 10 == 0:\n",
    "                # img.save(os.path.join(timestamp_dir, \"synth_{}_epo{}_{}.png\".format(i, epoch+1, timestr)))\n",
    "                # print(\"\\nSynthetic image saved with name synth_{}_epo{}_{}.png\".format(i, epoch+1, timestr))\n",
    "                img.save(os.path.join(timestamp_dir, \"synth_{}_epo{}.png\".format(i, epoch+1)))\n",
    "                if (i==0):\n",
    "                    print(\"\\nImmagine generata: synth_{}_epo{}.png\".format(i, epoch+1))\n",
    "                else:\n",
    "                    print(\"Immagine generata: synth_{}_epo{}.png\".format(i, epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inizializzo parametri wandb\n",
    "\n",
    "Usati per il logging sul sito utilizzato per tracciare gli esperimenti. Non rilevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"wandb_projectname\", entity=\"wandb_username\", \n",
    "        config= {\n",
    "                \"dataset\": seed_name,\n",
    "                \"train_samples\": nb_train_samples,\n",
    "                \"validation_samples\": nb_validation_samples,\n",
    "                \"synth_samples\": nb_synth_samples,\n",
    "                \"test_samples\": nb_test_samples,\n",
    "                \"latent_dim\": latent_dim,\n",
    "                \"lr_discr\": lr_disc,\n",
    "                \"decay_discr\": decay_disc,\n",
    "                \"lr_gen\": lr_gen,\n",
    "                \"decay_gen\": decay_gen,\n",
    "                \"n_epochs\": n_epochs,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"norm\": nl,\n",
    "                \"loss_func\": loss_func,\n",
    "                \"label_smoothing\": lbl_smooth,\n",
    "                }\n",
    ")\n",
    "config = wandb.config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=lr_disc, beta_1=decay_disc), \n",
    "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=lr_gen, beta_1=decay_gen),   \n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(),\n",
    "    train_mse_metric=tf.keras.metrics.MeanSquaredError(name='mse'),                 # aggiunto\n",
    "    train_acc_metric=tf.keras.metrics.BinaryAccuracy(name='accuracy')               # aggiunto\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stampo riepilogo degli iperparametri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non rilevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training di una C-GAN ...')\n",
    "print(f'- dataset: ', seed_name)\n",
    "print(f'- lista delle classi: ', class_names_train)\n",
    "print(f'- # di classi: ', n_classes)\n",
    "print(f'- # di campioni per il training: ', nb_train_samples)\n",
    "print(f'- # di campioni per la validation: ', nb_validation_samples)\n",
    "print(f'- # di campioni per il test: ', nb_test_samples)\n",
    "print(f'- # totale di campioni: ', total_nb_samples) \n",
    "print(f'- percentuale di campioni per il training: ', round(nb_train_samples/total_nb_samples*100, 2), '%')\n",
    "print(f'- percentuale di campioni per la validation: ', round(nb_validation_samples/nb_train_samples*100), '%')\n",
    "print(f'- percentuale di campioni per il test: ', round(nb_test_samples/total_nb_samples*100, 2), ' %')\n",
    "print(f'- dimensioni dello spazio latente: ', latent_dim)\n",
    "print(f'- # di epochs: ', n_epochs - 1)\n",
    "print(f'- diemnsioni dei batch: ', batch_size)\n",
    "print(f'- learning rate disc.: ', lr_disc)\n",
    "print(f'- learning rate gen.: ', lr_gen)\n",
    "print(f'- normalizzazione: ', nl)\n",
    "print(f'- # di validation steps: ', round(validation_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inizio training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cond_gan.fit(\n",
    "    normalized_train_ds,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(normalized_val_ds),\n",
    "    validation_steps=3, # generalmente validation_steps = validation_samples / batch_size\n",
    "    callbacks=[GANMonitor(num_img=5), get_callbacks(log_dir=log_dir), WandbCallback()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salvo il modello del generatore finale per utilizzo futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_generator = cond_gan.generator\n",
    "# trained_generator.save(\"models/cgan_gen_\" + str(seed_name) + \"_epoch\" + str(n_epochs) + \"_\" + str(timestr) + \".h5\")\n",
    "# print(\"Modello salvato.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fase di test\n",
    "Uso il metodo model.evaluate() per avere le metriche corrispondenti al test dataset.\n",
    "\n",
    "Ciò è possibile solo dopo l'override del train_step del metodo model.fit(), altrimenti restituisce errore per il subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = cond_gan.evaluate(normalized_test_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stampo le metriche come dataframe\n",
    "(nel caso non volessi utilizzare wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:<15} {:<10}\".format('Metric','Value'))\n",
    "metric_value = []\n",
    "for k, v in evaluate.items():\n",
    "    metric, value = k, v\n",
    "    print(\"{:<15} {:<10}\".format(\"test_\"+metric, value))\n",
    "    metric_value.append(evaluate.get(metric))\n",
    "print(metric_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggiungo le metriche del test dataset al csv generato dal callback\n",
    "(nel caso non volessi utilizzare wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)\n",
    "df['test_accuracy'] = metric_value[3]\n",
    "df['test_mse'] = metric_value[2]\n",
    "df['test_d_loss'] = metric_value[1]\n",
    "df['test_g_loss'] = metric_value[0]\n",
    "df['dataset_name'] = seed_name\n",
    "df.to_csv(csv_file)\n",
    "last_row = df.iloc[-1]\n",
    "print(last_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Termino il logging su wandb\n",
    "1) Logging manuale delle metriche di test\n",
    "2) Invio email al termine del training\n",
    "3) Termino la run e salvo i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"test_g_loss\": metric_value[0], \"test_d_loss\": metric_value[1], \"test_mse\": metric_value[2], \"test_accuracy\": metric_value[3]})\n",
    "wandb.alert(title=\"Run finished\", text=\"Run finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caricamento weights da un'eventuale checkpoint e successiva compilazione per avere modello completo.\n",
    "Il file del modello verrà utilizzato nello script per la generazione delle immagini \"image_generation.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_file = \"logs/model_checkpoints/20220508-010316 mea02_1000epo/cp-epo0030-g_loss0.78-d_loss0.66-acc0.66-mse0.23\"\n",
    "# cp_name = \"cp-epo0030-g_loss0.78-d_loss0.66-acc0.66-mse0.23\"\n",
    "# cond_gan.load_weights(weight_file).expect_partial()\n",
    "# print(\"Weights caricati con successo. Modello pronto per essere compilato\")\n",
    "\n",
    "# best_trained_generator = cond_gan.generator\n",
    "# best_trained_generator.compile()\n",
    "# timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "# best_trained_generator.save(\"models/best_cgan_gen_\" + cp_name + \"_\" + str(timestr) + \".h5\")\n",
    "# print(\"Modello migliore salvato.\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c47b1065398c2163c640202fad4fcf79d15a59777db3d8c704111e37697c1cab"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
